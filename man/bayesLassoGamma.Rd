% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bayesLassoGamma.R
\name{bayesLassoGamma}
\alias{bayesLassoGamma}
\title{Function to perform Bayesian lasso in linear regression}
\usage{
bayesLassoGamma(x, y, T = 10000, B = 5000)
}
\arguments{
\item{x}{Matrix of predictors, size n by p. Should be centered and scaled before calling the function.}

\item{y}{Matrix of response, size p by 1. Should be centered before calling the function.}

\item{T}{Total number of iterations for Gibbs sampler}

\item{B}{Burn-in iterations for Gibbs sampler.Here burn-in ietrations are not counted as part of Total iterations.}
}
\value{
Returns a matrix of beta coefficients after discarding burn-in iterations,
size Total*p.
}
\description{
Consider the model \eqn{y = x\beta+\epsilon} where \eqn{y = (y_1,...,y_n)} are \eqn{n} responses
and \eqn{\epsilon \sim N(0,\sigma^2)}.
The function is based on Park and Casella (2008) and computes \eqn{\beta} estimates from posterior distribution.
Gibbs sampler generates \eqn{\beta} from multivariate normal distribution,
\eqn{\sigma^2} from inverse gamma, \eqn{\tau_i^{-2}} from inverse gaussian and
\eqn{\lambda^2} from gamma distribution. The algorithm for sampling from inverse gaussian
distribution is based on Michael, Schucany and Haas (1976).
}
\details{
Gibbs sampler is based on the following full conditional distributions:

\eqn{\beta|. \sim MN(A^{-1}X'y,\sigma^2 * A^{-1}) } where
\eqn{ A=X'X+{D}_\tau^{-1} }

\eqn{ \sigma^2|. \sim IG( (1/2) * (n-1+p), (1/2) * [(y-X\beta)'(y-X\beta) + \beta'{D}_\tau^{-1}\beta] ) }

\eqn{ \tau_i^{-2}|. \sim Inverse-Gaussian (sqrt(\lambda^2 * \sigma^2 / \beta_i^2), \lambda^2) }

\eqn{\lambda^2|. \sim Gamma(p+r, \delta+\sum_{i=1}^{p}[ (\tau_i^2)/2) ] ) }
}
\examples{
x <- matrix(0, nrow=60, ncol=7)
e <- numeric(60)
sigma <- 2.5
for (i in 1:60){
 x[i,] <- stats::rnorm(7, 0, 1)
 e[i] <- stats::rnorm(1,0,sd=sigma^2)
}
y <- numeric(60)
for (i in 1:60){
 y[i] <- 3*x[i,4]+4*x[i,5]+e[i]
}
y <- y - mean(y) # centered y
bayesLassoGamma(x,y) # we expect only fourth and fifth coefficient to be far from zero
}
\references{
Park T, & Casella G. (2008). The Bayesian Lasso. Journal of the American Statistical Association,
103:482, 681-686, DOI: 10.1198/016214508000000337

Michael, John R.; Schucany, William R.; Haas, Roy W. (1976),
"Generating Random Variates Using Transformations with Multiple Roots",
The American Statistician, 30 (2): 88â€“90, doi:10.1080/00031305.1976.10479147, JSTOR 2683801
}
